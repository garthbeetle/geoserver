import psycopg2
import sys, csv
import os
from glob import glob

#Use pyscopg2 to create connection and then cursor. Will user cursor.execute() to do sql

conn = psycopg2.connect("host='localhost' dbname='census2011' user='postgres' password='password'")
cursor = conn.cursor()
#Get csv names using glob module to print all files from dir. Remember double backslash for windows!

csvNames =  glob('D:\\abs\\census2011\\2011_BCP_SA1_for_NSW_short-header\\2011 Census BCP Statistical Areas Level 1 for NSW\\NSW\\*')

#for every csv file name open file of that name, read first row
#and second row, get type of second row and use that to create an
#sql create table statement with types
#print ERROR if error

directory = 'D:\\abs\\census2011\\2011_BCP_SA1_for_NSW_short-header\\2011 Census BCP Statistical Areas Level 1 for NSW\\NSW\\*'

def createTables(directory, primary):
"""takes a dir and adds tables in postgres for every csv file, column 
for every header, taking primary as a string for a common primary key
and uploads their contained data"""
	csvNames =  glob(directory)
	sql_strings = []
	for file in csvNames:
		with open(file, 'rb') as f:
			r = csv.reader(f)
			headers = r.next()
			types = r.next()
			tablename = 'a' + os.path.splitext(os.path.basename(file))[0]
			columns = ','.join('%s float' % name for name in headers)
			sql_string = ("CREATE TABLE %s (%s);" % (tablename, columns))
			cursor.execute(sql_string)
			conn.commit()
			cursor.execute("ALTER TABLE %s ADD PRIMARY KEY (%s);" % (tablename, primary))
			conn.commit()
			cursor.execute("Copy %s from '%s' with delimiter ',' csv header;" %(tablename,file))
			conn.commit()

conn.close()
	
#in that same loop, after the creation of the table, import the csv data
#with another sql statement

#print ERROR if error

#done.



###cursor.close()
###conn.close()
